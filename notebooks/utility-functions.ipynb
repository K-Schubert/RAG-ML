{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dda713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tqdm\n",
    "import glob\n",
    "import re\n",
    "import PyPDF2\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60a0d4b-e876-4ef5-b977-70795088406c",
   "metadata": {},
   "source": [
    "# Create master list of papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e1ae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_paper_master_list(reset=False):\n",
    "\n",
    "    if reset:\n",
    "        open(\"../data/pdfs/arxiv_master_list.txt\", \"w\").close()\n",
    "    \n",
    "    with open(\"../data/pdfs/arxiv_master_list.txt\", \"r\") as infile:\n",
    "        arxiv_master_list = infile.read()\n",
    "\n",
    "    to_write = []\n",
    "\n",
    "    for _dir in glob.glob(\"../data/pdfs/*\"):\n",
    "\n",
    "        papers = glob.glob(f\"{_dir}/*.pdf\")\n",
    "        arxiv_ids = [paper.split(\"/\")[-1].replace(\".pdf\", \"\") for paper in papers]\n",
    "\n",
    "        for _id in arxiv_ids:\n",
    "            if _id not in arxiv_master_list:\n",
    "                to_write.append(_id)\n",
    "\n",
    "    with open(\"../data/pdfs/arxiv_master_list.txt\", \"a\") as outfile:\n",
    "        outfile.write(\"\\n\".join(to_write))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aff7d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_paper_master_list(reset=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ff5203",
   "metadata": {},
   "source": [
    "# Remove duplicated papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d58125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicated_papers():\n",
    "    \n",
    "    with open(\"../data/pdfs/arxiv_master_list.txt\", \"r\") as infile:\n",
    "        arxiv_master_list = infile.read()\n",
    "\n",
    "    all_papers = {}\n",
    "\n",
    "    duplicated_papers = dict(Counter(arxiv_master_list.split(\"\\n\")))\n",
    "\n",
    "    # get all paper arxiv ids by category\n",
    "    for _dir in glob.glob(\"../data/pdfs/*/\"):\n",
    "\n",
    "        papers = glob.glob(f\"{_dir}/*.pdf\")\n",
    "        arxiv_ids = [paper.split(\"/\")[-1].replace(\".pdf\", \"\") for paper in papers]\n",
    "\n",
    "        all_papers[_dir] = arxiv_ids\n",
    "\n",
    "    # if a paper is duplicated, delete until only one is left\n",
    "    for doc, count in tqdm.tqdm(duplicated_papers.items()):\n",
    "\n",
    "        if count > 1:\n",
    "\n",
    "            dir_present = [doc in v for k,v in all_papers.items()]\n",
    "            idx = [i for i, x in enumerate(dir_present) if x]\n",
    "            directories = [list(all_papers.keys())[i] for i in idx]\n",
    "\n",
    "            while len(directories) > 1:\n",
    "                for directory in directories:\n",
    "                    os.remove(os.path.join(directory, f\"{doc}.pdf\"))\n",
    "                    directories.remove(directory)\n",
    "\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd017d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_duplicated_papers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8529d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# once duplicated papers have been delete, reinitialise master list\n",
    "create_paper_master_list(reset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0bdaa0-8e55-4e3f-9f3d-1e37125da69f",
   "metadata": {},
   "source": [
    "# Parse PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca16ff57-dce3-4d68-8056-4f35c2b9cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pdfs_to_text(cat):\n",
    "\n",
    "    # replace arxiv id \".\" with \"_\" in filenames\n",
    "    pdfs = glob.glob(f\"../data/pdfs/{cat.replace('.', '_')}/*.pdf\")\n",
    "\n",
    "    for pdf in pdfs:\n",
    "\n",
    "        new_name = re.sub(r\"(\\d+)\\.(\\d+)\", r\"\\1_\\2\", pdf)\n",
    "        os.rename(pdf, new_name)\n",
    "    \n",
    "    # need to read new names with \"_\" instead of \".\" in arxiv id\n",
    "    pdfs = glob.glob(f\"../data/pdfs/{cat.replace('.', '_')}/*.pdf\")\n",
    "\n",
    "    for pdf in tqdm.tqdm(pdfs):\n",
    "\n",
    "        text = []\n",
    "\n",
    "        with open(pdf, \"rb\") as infile:\n",
    "\n",
    "            try:\n",
    "                parsed_pdf = PyPDF2.PdfReader(infile)\n",
    "\n",
    "                for page in range(len(parsed_pdf.pages)):\n",
    "\n",
    "                    page_obj = parsed_pdf.pages[page]\n",
    "                    text.append(page_obj.extract_text())\n",
    "\n",
    "                text = \"\\n\".join(text)\n",
    "\n",
    "                paper_id = re.search('(\\d+.*)\\.pdf', pdf).group(1)\n",
    "\n",
    "                with open(f\"../data/txt/full_papers/{cat.replace('.', '_')}/{paper_id}.txt\", \"w\") as outfile:\n",
    "                    outfile.write(text)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"{pdf}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe43e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_pdfs_to_text(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0dd405-7b50-4881-9766-5ebdfe0166ca",
   "metadata": {},
   "source": [
    "### Remove papers with 0 byte size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa326c1-c6a6-4d96-be5d-8fb3de7ab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_empty_files(cat):\n",
    "\n",
    "    docs = glob.glob(f\"../data/txt/full_papers/{cat.replace('.', '_')}/*.txt\")\n",
    "\n",
    "    for doc in docs:\n",
    "\n",
    "        size = os.path.getsize(doc)\n",
    "\n",
    "        if size == 0:\n",
    "\n",
    "            os.remove(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f35a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_empty_files(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b9d949-9c58-4fef-b61f-021f82bae89a",
   "metadata": {},
   "source": [
    "### Extract references and content (without LLM) and append to \"csXXpapers_aug.jsonl\" master file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8988d31-feec-4b4d-8cfc-140adfc19797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_refs_content(cat):\n",
    "\n",
    "    arxiv_data = pd.read_json(f\"../data/{cat.replace('.', '_')}papers.jsonl\", lines=True)\n",
    "    arxiv_ids = arxiv_data[\"entry_id\"].apply(lambda x: x.split(\"/\")[-1].replace(\".\", \"_\"))\n",
    "\n",
    "    papers = glob.glob(f\"../data/txt/full_papers/{cat.replace('.', '_')}/*.txt\")\n",
    "\n",
    "    for paper_path in tqdm.tqdm(papers):\n",
    "\n",
    "        # save references to .txt file\n",
    "        with open(paper_path, \"r\") as infile:\n",
    "            paper = infile.read()\n",
    "\n",
    "        references = paper.split(\"\\nReferences\\n\")[-1]\n",
    "        if len(references) != 2:\n",
    "            references = paper.split(\"\\nREFERENCES\\n\")[-1]\n",
    "        else:\n",
    "            references = \"No references found\"\n",
    "\n",
    "        paper_id = paper_path.split(\"/\")[-1]\n",
    "\n",
    "        with open(f\"../data/txt/references/{cat.replace('.', '_')}/{paper_id}\", \"w\") as outfile:\n",
    "            outfile.write(references)\n",
    "\n",
    "        # append references to \"cs_XXpapers.jsonl\"\n",
    "        try:\n",
    "            id = arxiv_ids[arxiv_ids == paper_id.replace(\".txt\", \"\")].index.values[0]\n",
    "            arxiv_data.loc[id, \"references\"] = str(references)\n",
    "        except Exception as e:\n",
    "            print(paper_id)\n",
    "\n",
    "        # save content to .txt file\n",
    "        content = paper.split(\"\\nReferences\\n\")[0]\n",
    "\n",
    "        with open(f\"../data/txt/content/{cat.replace('.', '_')}/{paper_id}\", \"w\") as outfile:\n",
    "            outfile.write(content)\n",
    "\n",
    "        # append content to \"cs_XXpapers.jsonl\"\n",
    "        try:\n",
    "            id = arxiv_ids[arxiv_ids == paper_id.replace(\".txt\", \"\")].index.values[0]\n",
    "            arxiv_data.loc[id, \"content\"] = str(content)\n",
    "        except Exception as e:\n",
    "            print(paper_id)\n",
    "            \n",
    "    with open(f\"../data/{cat.replace('.', '_')}papers_aug.jsonl\", \"w\") as f:\n",
    "        f.write(arxiv_data.to_json(orient='records', lines=True, force_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec9a61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_refs_content(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5764b57",
   "metadata": {},
   "source": [
    "# Create version of cs_XXpapers.jsonl with valid \"content\" field (not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f566f9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"cs_CL\"\n",
    "\n",
    "arxiv_data = pd.read_json(f\"../data/{cat.replace('.', '_')}papers_aug.jsonl\", lines=True)\n",
    "arxiv_data.dropna(subset=[\"content\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c1d28e-93ed-41f1-b069-a99b87bc8af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../data/{cat.replace('.', '_')}papers_aug_clean.jsonl\", \"w\") as f:\n",
    "    f.write(arxiv_data.to_json(orient='records', lines=True, force_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfa33d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e55e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b7b4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "103fb976-3db1-4e0e-a8d0-747de0172bfa",
   "metadata": {},
   "source": [
    "# Check references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bad126-d937-4b98-8e57-3d19fef60a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../data/txt/references/{cat.replace('.', '_')}/2309_09958v1.txt\", \"r\") as infile:\n",
    "    paper = infile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55812ebc-4c22-4412-a5d3-c850c46c5403",
   "metadata": {},
   "outputs": [],
   "source": [
    "references = paper.split(\"\\nReferences\\n\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2e7d28-af56-42f1-aec5-14df8daac661",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7f5e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_rag",
   "language": "python",
   "name": "venv_rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
