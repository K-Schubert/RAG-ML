{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ddb51d-3303-410b-8eab-9cc50d6750c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain.agents import Tool\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa033729-0b74-4c4f-97a7-f776411801eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Load env variables\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6144fca7-5fd7-4d00-8f33-039ebd9a891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bc0add-68ad-41c2-86ce-074ee2a07e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_math = LLMMathChain(llm=llm)\n",
    "\n",
    "# initialize the math tool\n",
    "math_tool = Tool(\n",
    "    name='Calculator',\n",
    "    func=llm_math.run,\n",
    "    description='Useful for when you need to answer questions about math.'\n",
    ")\n",
    "# when giving tools to LLM, we must pass as list of tools\n",
    "tools = [math_tool]\n",
    "\n",
    "tools[0].name, tools[0].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a499be1-9374-4adc-a4f4-e04d2ee822fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There already exists prebuilt tools in Langchain (load_tools to load them)\n",
    "\n",
    "tools = load_tools(\n",
    "    ['llm-math'],\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d4475f-a578-44e3-a434-7f633c115f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools[0].name, tools[0].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfdd322-04c6-4fc6-8c6c-3749abf069fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools[0].func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317e0f51-bb44-4156-8f1d-cf4eb95a8dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.name for x in tools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b093b9d0-b680-4452-ae51-96a79aa4e987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReAct agent: Agent framework where Agent will reason on prompt, decide on action and pass information to the action item (tool)\n",
    "# -> Agent receives a response from the tool and repeats reasoning process and action\n",
    "# Agent decides which action to take based on tool description\n",
    "# Define max_iterations to avoid infinite loop of reasoning/actions\n",
    "# Set verbose=False to only show final Agent output\n",
    "\n",
    "zero_shot_agent = initialize_agent(\n",
    "\tagent=\"zero-shot-react-description\", # zero-shot agent looks only at current prompt (no memory), focuses on current task only, one interaction only\n",
    "\ttools=tools,\n",
    "\tllm=llm,\n",
    "\tverbose=True,\n",
    "\tmax_iterations=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb11518f-88c9-4860-b445-4fce68270f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_agent(\"what is (4.5*2.1)^2.2?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3749df1a-fd28-4193-8aae-af0f1192cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_agent(\"if Mary has four apples and Giorgio brings two and a half apple \"\n",
    "                \"boxes (apple box contains eight apples), how many apples do we \"\n",
    "                \"have?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b83894a-5672-42f5-a860-b28c4f1e6e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_agent(\"what is the capital of Norway?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763e1a7e-a630-472a-9b63-9a02c8190f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"{query}\"\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# initialize the LLM tool\n",
    "llm_tool = Tool(\n",
    "    name='Language Model',\n",
    "    func=llm_chain.run,\n",
    "    description='use this tool for general purpose queries and logic'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bcca5d-acd2-45ca-9372-0d85a13e1f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.append(llm_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da915870-c8a4-43c5-99e5-379a8f787c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1dfd7e-7634-4e03-b0d6-93e98d99e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_agent(\"what is the capital of Norway?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88af4e93-1cc6-413e-ab2b-6e07fa8f8751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c91d6bd-5de4-4ca3-b6bb-1f10b3c8cf6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "286844d5-085c-4a05-8d57-40174cb7e928",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c0ba56-9462-4bc2-9ffc-1be4ad621411",
   "metadata": {},
   "source": [
    "When building an Agent, we need to:\n",
    "\n",
    "- define the tools or the toolkit\n",
    "- define the llm\n",
    "- define the agent type\n",
    "\n",
    "First, we have the tools which are included in the prompt. Second we have a thought process which was before was immediate in chains but now involves a 'thought', 'action', 'action input', 'observation' sequence.\n",
    "\n",
    "Suffice it to say for now that the LLM now has the ability to 'reason' on how to best use tools to solve our query and can combine them in intelligent ways with just a brief description of each of them. If you want to learn more about this paradigm (MRKL) in detail, please refer to this paper.\n",
    "\n",
    "Finally, let's pay attention to the 'agent_scratchpad'. What is that? Well, that is where we will be appending every thought or action that the agent has already performed. In this way, at each point in time, the agent will know what it has found out and will be able to continue its thought process. In other words, after using a tool it adds its thoughts and observations to the scratchpad and picks up from there.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04674c9-52ef-431c-8c4c-294cdcdce45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "\n",
    "llm = OpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3543dc4d-152c-4d89-bf07-fb402a3e6cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "def count_tokens(agent, query):\n",
    "    with get_openai_callback() as cb:\n",
    "        result = agent(query)\n",
    "        print(f'Spent a total of {cb.total_tokens} tokens')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9bbaf0-4ed7-42bd-8b79-9c15f0b4936b",
   "metadata": {},
   "source": [
    "# Zero Shot ReAct Agent - SQL DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e316b06-e389-4186-90c1-9be2a11f65a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import MetaData\n",
    "from sqlalchemy import Column, Integer, String, Table, Date, Float\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import insert\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain.utilities import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b577993a-4df6-49ea-ad70-1b4ec06b8f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_obj = MetaData()\n",
    "\n",
    "stocks = Table(\n",
    "    \"stocks\",\n",
    "    metadata_obj,\n",
    "    Column(\"obs_id\", Integer, primary_key=True),\n",
    "    Column(\"stock_ticker\", String(4), nullable=False),\n",
    "    Column(\"price\", Float, nullable=False),\n",
    "    Column(\"date\", Date, nullable=False),\n",
    ")\n",
    "\n",
    "engine = create_engine(\"sqlite:///:memory:\")\n",
    "metadata_obj.create_all(engine)\n",
    "\n",
    "observations = [\n",
    "    [1, 'ABC', 200, datetime(2023, 1, 1)],\n",
    "    [2, 'ABC', 208, datetime(2023, 1, 2)],\n",
    "    [3, 'ABC', 232, datetime(2023, 1, 3)],\n",
    "    [4, 'ABC', 225, datetime(2023, 1, 4)],\n",
    "    [5, 'ABC', 226, datetime(2023, 1, 5)],\n",
    "    [6, 'XYZ', 810, datetime(2023, 1, 1)],\n",
    "    [7, 'XYZ', 803, datetime(2023, 1, 2)],\n",
    "    [8, 'XYZ', 798, datetime(2023, 1, 3)],\n",
    "    [9, 'XYZ', 795, datetime(2023, 1, 4)],\n",
    "    [10, 'XYZ', 791, datetime(2023, 1, 5)],\n",
    "]\n",
    "     \n",
    "def insert_obs(obs):\n",
    "    stmt = insert(stocks).values(\n",
    "    obs_id=obs[0],\n",
    "    stock_ticker=obs[1],\n",
    "    price=obs[2],\n",
    "    date=obs[3]\n",
    "    )\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(stmt)\n",
    "\n",
    "\n",
    "\n",
    "for obs in observations:\n",
    "    insert_obs(obs)\n",
    "     \n",
    "db = SQLDatabase(engine)\n",
    "sql_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7fba7a-9500-44b2-a0cf-4d9dab2c24fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.agents.agent_types import AgentType\n",
    "\n",
    "agent_executor = create_sql_agent(\n",
    "    llm=llm,\n",
    "    toolkit=SQLDatabaseToolkit(db=db, llm=llm),\n",
    "    verbose=True,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    max_iterations=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4892e8f8-a019-41f6-abae-b81a5e77ba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = count_tokens(\n",
    "    agent_executor,\n",
    "    \"What is the multiplication of the ratio between stock \" +\n",
    "    \"prices for 'ABC' and 'XYZ' in January 3rd and the ratio \" +\n",
    "    \"between the same stock prices in January the 4th?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7cff70-cf7f-4e28-b8a6-8ac09de45c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_executor.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec976ba-d619-4297-97f6-c10392197bd0",
   "metadata": {},
   "source": [
    "# Conversational ReAct Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adedce4-61a2-4631-9843-5d21f080702a",
   "metadata": {},
   "source": [
    "The zero shot agent is really interesting but, as we said before, it has no memory. What if we want an assistant that remembers things we have talked about and can also reason about them and use tools? For that we have the conversational react agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7a8076-5fe5-4cd9-8e7b-c6de5cf9f148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "tools = load_tools(\n",
    "    [\"llm-math\"],\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b36574-d252-4548-afbd-2505b5530f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bc6483-8bc5-459e-a4a3-7c93b1714ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "conversational_agent = initialize_agent(\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8e6422-8696-49b8-8e5e-fcb93ba71b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = count_tokens(\n",
    "    conversational_agent,\n",
    "    \"What's the result of an investment of $10,000 growing at 8% annually for 5 years with compound interest?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b957d50-a4c3-4fa1-ad49-193d6b9420bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conversational_agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdc18c3-86bc-42e3-9705-39cdb5e3e5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = count_tokens(\n",
    "    conversational_agent,\n",
    "    \"If we start with $15,000 instead and follow the same 8% annual growth for 5 years with compound interest, how much more would we have compared to the previous scenario?\"\n",
    ")   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2e3c86-7cc8-4909-abf7-24e34ee7862d",
   "metadata": {},
   "source": [
    "# React Docstore Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415493ae-98e0-4b65-b310-4cedb98d7355",
   "metadata": {},
   "source": [
    "This type of agent is similar to the ones we have seen so far but it includes the interaction with a docstore. It will have two and only two tools at its disposal: 'Search' and 'Lookup'.\n",
    "\n",
    "With 'Search' it will bring up a relevant article and with 'Lookup' the agent will find the right piece of information in the article. This is probably easiest to see in an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507806bc-18f3-4fd7-8a2b-fb68edaa9321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import Wikipedia\n",
    "from langchain.agents.react.base import DocstoreExplorer, Tool\n",
    "\n",
    "docstore=DocstoreExplorer(Wikipedia())\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=docstore.search,\n",
    "        description='search wikipedia'\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Lookup\",\n",
    "        func=docstore.lookup,\n",
    "        description='lookup a term in wikipedia'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517951fb-d3a5-4d52-a163-a2e1a847afb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "docstore_agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=\"react-docstore\",\n",
    "    verbose=True,\n",
    "    max_iterations=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e30f0a-b6e0-4935-983a-fe108ca5c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tokens(docstore_agent, \"What were Archimedes' last words?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da5369-0250-440b-9dfa-f0d3353b4270",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docstore_agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5f6396-1cf9-4a40-a7c6-3769a259dd2f",
   "metadata": {},
   "source": [
    "# Self-Ask Agent with Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc28c774-2de2-4f35-aff4-dee534185645",
   "metadata": {},
   "source": [
    "This is the first-choice agent to use when using LLM's to extract information with a search engine. The agent will ask follow-up questions and use the search functionality to get intermediate answers that help it get to a final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59996b11-6403-4ee8-9abd-4e53bf3f2a37",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for SerpAPIWrapper\n__root__\n  Could not import serpapi python package. Please install it with `pip install google-search-results`. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI, SerpAPIWrapper\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initialize_agent, Tool\n\u001b[0;32m----> 4\u001b[0m search \u001b[38;5;241m=\u001b[39m \u001b[43mSerpAPIWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserpapi_api_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mapi_key\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m tools \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     Tool(\n\u001b[1;32m      7\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIntermediate Answer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     )\n\u001b[1;32m     11\u001b[0m ]\n\u001b[1;32m     13\u001b[0m self_ask_with_search \u001b[38;5;241m=\u001b[39m initialize_agent(tools, llm, agent\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself-ask-with-search\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/RAG-ML-chatbot/venv_rag/lib/python3.11/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for SerpAPIWrapper\n__root__\n  Could not import serpapi python package. Please install it with `pip install google-search-results`. (type=value_error)"
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI, SerpAPIWrapper\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "\n",
    "search = SerpAPIWrapper(serpapi_api_key='api_key')\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Intermediate Answer\",\n",
    "        func=search.run,\n",
    "        description='google search'\n",
    "    )\n",
    "]\n",
    "\n",
    "self_ask_with_search = initialize_agent(tools, llm, agent=\"self-ask-with-search\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ab4f13-c44a-41e0-8422-1bcba7c0039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(self_ask_with_search.agent.llm_chain.prompt.template)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_rag",
   "language": "python",
   "name": "venv_rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
